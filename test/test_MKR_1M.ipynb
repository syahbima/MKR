{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import FloatProgress, IntProgress\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load python file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../src/logger.py\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "class Logger:\n",
    "\n",
    "    def set_default_filename(self, filename):\n",
    "        self.default_filename = filename\n",
    "\n",
    "    def create_session_folder(self, path):\n",
    "        try:  \n",
    "            os.makedirs(path)\n",
    "        except OSError:  \n",
    "            print (\"Creation of the directory %s failed\" % path)\n",
    "        else:  \n",
    "            print (\"\\n ===> Successfully created the directory %s \\n\" % path)\n",
    "\n",
    "    def log(self, text):\n",
    "        with open(self.default_filename, 'a') as f:\n",
    "            f.writelines(text)\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    def save_model(self, model, filename):\n",
    "        pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../src/layers.py\n",
    "import tensorflow as tf\n",
    "from abc import abstractmethod\n",
    "\n",
    "LAYER_IDS = {}\n",
    "\n",
    "\n",
    "def get_layer_id(layer_name=''):\n",
    "    if layer_name not in LAYER_IDS:\n",
    "        LAYER_IDS[layer_name] = 0\n",
    "        return 0\n",
    "    else:\n",
    "        LAYER_IDS[layer_name] += 1\n",
    "        return LAYER_IDS[layer_name]\n",
    "\n",
    "\n",
    "class Layer(object):\n",
    "    def __init__(self, name):\n",
    "        if not name:\n",
    "            layer = self.__class__.__name__.lower()\n",
    "            name = layer + '_' + str(get_layer_id(layer))\n",
    "        self.name = name\n",
    "        self.vars = []\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        outputs = self._call(inputs)\n",
    "        return outputs\n",
    "\n",
    "    @abstractmethod\n",
    "    def _call(self, inputs):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Dense(Layer):\n",
    "    def __init__(self, input_dim, output_dim, dropout=0.0, act=tf.nn.relu, name=None):\n",
    "        super(Dense, self).__init__(name)\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.dropout = dropout\n",
    "        self.act = act\n",
    "        with tf.variable_scope(self.name):\n",
    "            self.weight = tf.get_variable(name='weight', shape=(input_dim, output_dim), dtype=tf.float32)\n",
    "            self.bias = tf.get_variable(name='bias', shape=output_dim, initializer=tf.zeros_initializer())\n",
    "        self.vars = [self.weight]\n",
    "\n",
    "    def _call(self, inputs):\n",
    "        x = tf.nn.dropout(inputs, 1-self.dropout)\n",
    "        output = tf.matmul(x, self.weight) + self.bias\n",
    "        return self.act(output)\n",
    "\n",
    "\n",
    "class CrossCompressUnit(Layer):\n",
    "    def __init__(self, dim, name=None):\n",
    "        super(CrossCompressUnit, self).__init__(name)\n",
    "        self.dim = dim\n",
    "        with tf.variable_scope(self.name):\n",
    "            self.weight_vv = tf.get_variable(name='weight_vv', shape=(dim, 1), dtype=tf.float32)\n",
    "            self.weight_ev = tf.get_variable(name='weight_ev', shape=(dim, 1), dtype=tf.float32)\n",
    "            self.weight_ve = tf.get_variable(name='weight_ve', shape=(dim, 1), dtype=tf.float32)\n",
    "            self.weight_ee = tf.get_variable(name='weight_ee', shape=(dim, 1), dtype=tf.float32)\n",
    "            self.bias_v = tf.get_variable(name='bias_v', shape=dim, initializer=tf.zeros_initializer())\n",
    "            self.bias_e = tf.get_variable(name='bias_e', shape=dim, initializer=tf.zeros_initializer())\n",
    "        self.vars = [self.weight_vv, self.weight_ev, self.weight_ve, self.weight_ee]\n",
    "\n",
    "    def _call(self, inputs):\n",
    "        # [batch_size, dim]\n",
    "        v, e = inputs\n",
    "\n",
    "        # [batch_size, dim, 1], [batch_size, 1, dim]\n",
    "        v = tf.expand_dims(v, dim=2)\n",
    "        e = tf.expand_dims(e, dim=1)\n",
    "\n",
    "        # [batch_size, dim, dim]\n",
    "        c_matrix = tf.matmul(v, e)\n",
    "        c_matrix_transpose = tf.transpose(c_matrix, perm=[0, 2, 1])\n",
    "\n",
    "        # [batch_size * dim, dim]\n",
    "        c_matrix = tf.reshape(c_matrix, [-1, self.dim])\n",
    "        c_matrix_transpose = tf.reshape(c_matrix_transpose, [-1, self.dim])\n",
    "\n",
    "        # [batch_size, dim]\n",
    "        v_output = tf.reshape(tf.matmul(c_matrix, self.weight_vv) + tf.matmul(c_matrix_transpose, self.weight_ev),\n",
    "                              [-1, self.dim]) + self.bias_v\n",
    "        e_output = tf.reshape(tf.matmul(c_matrix, self.weight_ve) + tf.matmul(c_matrix_transpose, self.weight_ee),\n",
    "                              [-1, self.dim]) + self.bias_e\n",
    "\n",
    "        return v_output, e_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../src/model.py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "class MKR(object):\n",
    "    def __init__(self, args, n_users, n_items, n_entities, n_relations):\n",
    "        self._parse_args(n_users, n_items, n_entities, n_relations)\n",
    "        self._build_inputs()\n",
    "        self._build_model(args)\n",
    "        self._build_loss(args)\n",
    "        self._build_train(args)\n",
    "\n",
    "    def _parse_args(self, n_users, n_items, n_entities, n_relations):\n",
    "        self.n_user = n_users\n",
    "        self.n_item = n_items\n",
    "        self.n_entity = n_entities\n",
    "        self.n_relation = n_relations\n",
    "\n",
    "        # for computing l2 loss\n",
    "        self.vars_rs = []\n",
    "        self.vars_kge = []\n",
    "\n",
    "    def _build_inputs(self):\n",
    "        self.user_indices = tf.placeholder(tf.int32, [None], 'user_indices')\n",
    "        self.item_indices = tf.placeholder(tf.int32, [None], 'item_indices')\n",
    "        self.labels = tf.placeholder(tf.float32, [None], 'labels')\n",
    "        self.head_indices = tf.placeholder(tf.int32, [None], 'head_indices')\n",
    "        self.tail_indices = tf.placeholder(tf.int32, [None], 'tail_indices')\n",
    "        self.relation_indices = tf.placeholder(tf.int32, [None], 'relation_indices')\n",
    "\n",
    "    def _build_model(self, args):\n",
    "        self._build_low_layers(args)\n",
    "        self._build_high_layers(args)\n",
    "\n",
    "    def _build_low_layers(self, args):\n",
    "        self.user_emb_matrix = tf.get_variable('user_emb_matrix', [self.n_user, args.dim])\n",
    "        self.item_emb_matrix = tf.get_variable('item_emb_matrix', [self.n_item, args.dim])\n",
    "        self.entity_emb_matrix = tf.get_variable('entity_emb_matrix', [self.n_entity, args.dim])\n",
    "        self.relation_emb_matrix = tf.get_variable('relation_emb_matrix', [self.n_relation, args.dim])\n",
    "\n",
    "        # [batch_size, dim]\n",
    "        self.user_embeddings = tf.nn.embedding_lookup(self.user_emb_matrix, self.user_indices)\n",
    "        self.item_embeddings = tf.nn.embedding_lookup(self.item_emb_matrix, self.item_indices)\n",
    "        self.head_embeddings = tf.nn.embedding_lookup(self.entity_emb_matrix, self.head_indices)\n",
    "        self.relation_embeddings = tf.nn.embedding_lookup(self.relation_emb_matrix, self.relation_indices)\n",
    "        self.tail_embeddings = tf.nn.embedding_lookup(self.entity_emb_matrix, self.tail_indices)\n",
    "\n",
    "        for _ in range(args.L):\n",
    "            user_mlp = Dense(input_dim=args.dim, output_dim=args.dim)\n",
    "            tail_mlp = Dense(input_dim=args.dim, output_dim=args.dim)\n",
    "            cc_unit = CrossCompressUnit(args.dim)\n",
    "            self.user_embeddings = user_mlp(self.user_embeddings)\n",
    "            self.item_embeddings, self.head_embeddings = cc_unit([self.item_embeddings, self.head_embeddings])\n",
    "            self.tail_embeddings = tail_mlp(self.tail_embeddings)\n",
    "\n",
    "            self.vars_rs.extend(user_mlp.vars)\n",
    "            self.vars_rs.extend(cc_unit.vars)\n",
    "            self.vars_kge.extend(tail_mlp.vars)\n",
    "            self.vars_kge.extend(cc_unit.vars)\n",
    "\n",
    "    def _build_high_layers(self, args):\n",
    "        # RS\n",
    "        use_inner_product = True\n",
    "        if use_inner_product:\n",
    "            # [batch_size]\n",
    "            self.scores = tf.reduce_sum(self.user_embeddings * self.item_embeddings, axis=1)\n",
    "        else:\n",
    "            # [batch_size, dim * 2]\n",
    "            self.user_item_concat = tf.concat([self.user_embeddings, self.item_embeddings], axis=1)\n",
    "            for _ in range(args.H - 1):\n",
    "                rs_mlp = Dense(input_dim=args.dim * 2, output_dim=args.dim * 2)\n",
    "                # [batch_size, dim * 2]\n",
    "                self.user_item_concat = rs_mlp(self.user_item_concat)\n",
    "                self.vars_rs.extend(rs_mlp.vars)\n",
    "\n",
    "            rs_pred_mlp = Dense(input_dim=args.dim * 2, output_dim=1)\n",
    "            # [batch_size]\n",
    "            self.scores = tf.squeeze(rs_pred_mlp(self.user_item_concat))\n",
    "            self.vars_rs.extend(rs_pred_mlp.vars)\n",
    "        self.scores_normalized = tf.nn.sigmoid(self.scores)\n",
    "\n",
    "        # KGE\n",
    "        # [batch_size, dim * 2]\n",
    "        self.head_relation_concat = tf.concat([self.head_embeddings, self.relation_embeddings], axis=1)\n",
    "        for _ in range(args.H - 1):\n",
    "            kge_mlp = Dense(input_dim=args.dim * 2, output_dim=args.dim * 2)\n",
    "            # [batch_size, dim]\n",
    "            self.head_relation_concat = kge_mlp(self.head_relation_concat)\n",
    "            self.vars_kge.extend(kge_mlp.vars)\n",
    "\n",
    "        kge_pred_mlp = Dense(input_dim=args.dim * 2, output_dim=args.dim)\n",
    "        # [batch_size, 1]\n",
    "        self.tail_pred = kge_pred_mlp(self.head_relation_concat)\n",
    "        self.vars_kge.extend(kge_pred_mlp.vars)\n",
    "        self.tail_pred = tf.nn.sigmoid(self.tail_pred)\n",
    "\n",
    "        self.scores_kge = tf.nn.sigmoid(tf.reduce_sum(self.tail_embeddings * self.tail_pred, axis=1))\n",
    "        self.rmse = tf.reduce_mean(\n",
    "            tf.sqrt(tf.reduce_sum(tf.square(self.tail_embeddings - self.tail_pred), axis=1) / args.dim))\n",
    "\n",
    "    def _build_loss(self, args):\n",
    "        # RS\n",
    "        self.base_loss_rs = tf.reduce_mean(\n",
    "            tf.nn.sigmoid_cross_entropy_with_logits(labels=self.labels, logits=self.scores))\n",
    "        self.l2_loss_rs = tf.nn.l2_loss(self.user_embeddings) + tf.nn.l2_loss(self.item_embeddings)\n",
    "        for var in self.vars_rs:\n",
    "            self.l2_loss_rs += tf.nn.l2_loss(var)\n",
    "        self.loss_rs = self.base_loss_rs + self.l2_loss_rs * args.l2_weight\n",
    "\n",
    "        # KGE\n",
    "        self.base_loss_kge = -self.scores_kge\n",
    "        self.l2_loss_kge = tf.nn.l2_loss(self.head_embeddings) + tf.nn.l2_loss(self.tail_embeddings)\n",
    "        for var in self.vars_kge:\n",
    "            self.l2_loss_kge += tf.nn.l2_loss(var)\n",
    "        self.loss_kge = self.base_loss_kge + self.l2_loss_kge * args.l2_weight\n",
    "\n",
    "    def _build_train(self, args):\n",
    "        self.optimizer_rs = tf.train.AdamOptimizer(args.lr_rs).minimize(self.loss_rs)\n",
    "        self.optimizer_kge = tf.train.AdamOptimizer(args.lr_kge).minimize(self.loss_kge)\n",
    "\n",
    "    def train_rs(self, sess, feed_dict):\n",
    "        return sess.run([self.optimizer_rs, self.loss_rs], feed_dict)\n",
    "\n",
    "    def train_kge(self, sess, feed_dict):\n",
    "        return sess.run([self.optimizer_kge, self.rmse], feed_dict)\n",
    "\n",
    "    def eval(self, sess, feed_dict):\n",
    "        labels, scores = sess.run([self.labels, self.scores_normalized], feed_dict)\n",
    "        auc = roc_auc_score(y_true=labels, y_score=scores)\n",
    "        predictions = [1 if i >= 0.5 else 0 for i in scores]\n",
    "        acc = np.mean(np.equal(predictions, labels))\n",
    "        return auc, acc\n",
    "\n",
    "    def get_scores(self, sess, feed_dict):\n",
    "        return sess.run([self.item_indices, self.scores_normalized], feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../src/train.py\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = str(datetime.timestamp(datetime.now()))\n",
    "\n",
    "# logger = Logger()\n",
    "# session_log_path = \"../log/{}/\".format(timestamp)\n",
    "# logger.create_session_folder(session_log_path)\n",
    "# logger.set_default_filename(session_log_path + \"log.txt\")\n",
    "\n",
    "\n",
    "def train(args, data, show_loss, show_topk):\n",
    "    logger.log(str(args))\n",
    "    n_user, n_item, n_entity, n_relation = data[0], data[1], data[2], data[3]\n",
    "    train_data, eval_data, test_data = data[4], data[5], data[6]\n",
    "    kg = data[7]\n",
    "\n",
    "    n_item = n_item\n",
    "\n",
    "    model = MKR(args, n_user, n_item, n_entity, n_relation)\n",
    "\n",
    "    print(\"n_user : \" , n_user, \"\\n\")\n",
    "    print(\"n_item : \" , n_item, \"\\n\")\n",
    "\n",
    "    # top-K evaluation settings\n",
    "    user_num = 100\n",
    "    k_list = [1, 2, 5, 10, 20, 50, 100]\n",
    "    train_record = get_user_record(train_data, True)\n",
    "    test_record = get_user_record(test_data, False)\n",
    "    user_list = list(set(train_record.keys()) & set(test_record.keys()))\n",
    "    if len(user_list) > user_num:\n",
    "        user_list = np.random.choice(user_list, size=user_num, replace=False)\n",
    "    \n",
    "    # item_set = set(list(range(n_item)))\n",
    "    item_set = set()\n",
    "\n",
    "    for data in train_data :\n",
    "        item_set.add(int(data[1]))\n",
    "\n",
    "    for data in eval_data :\n",
    "        item_set.add(int(data[1]))\n",
    "\n",
    "    for data in test_data :\n",
    "        item_set.add(int(data[1]))\n",
    "\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        saver = tf.train.Saver(max_to_keep=None)\n",
    "\n",
    "        for step in range(args.n_epochs):\n",
    "            # RS training\n",
    "            np.random.shuffle(train_data)\n",
    "            start = 0\n",
    "            while start < train_data.shape[0]:\n",
    "                _, loss = model.train_rs(sess, get_feed_dict_for_rs(model, train_data, start, start + args.batch_size))\n",
    "                start += args.batch_size\n",
    "                if show_loss:\n",
    "                    print(loss)\n",
    "\n",
    "            # KGE training\n",
    "            if step % args.kge_interval == 0:\n",
    "                np.random.shuffle(kg)\n",
    "                start = 0\n",
    "                while start < kg.shape[0]:\n",
    "                    _, rmse = model.train_kge(sess, get_feed_dict_for_kge(model, kg, start, start + args.batch_size))\n",
    "                    start += args.batch_size\n",
    "                    if show_loss:\n",
    "                        print(rmse)\n",
    "\n",
    "            # CTR evaluation\n",
    "            train_auc, train_acc = model.eval(sess, get_feed_dict_for_rs(model, train_data, 0, train_data.shape[0]))\n",
    "            eval_auc, eval_acc = model.eval(sess, get_feed_dict_for_rs(model, eval_data, 0, eval_data.shape[0]))\n",
    "            test_auc, test_acc = model.eval(sess, get_feed_dict_for_rs(model, test_data, 0, test_data.shape[0]))\n",
    "\n",
    "            print('epoch %d    train auc: %.4f  acc: %.4f    eval auc: %.4f  acc: %.4f    test auc: %.4f  acc: %.4f'\n",
    "                  % (step, train_auc, train_acc, eval_auc, eval_acc, test_auc, test_acc))\n",
    "            logger.log('epoch %d    train auc: %.4f  acc: %.4f    eval auc: %.4f  acc: %.4f    test auc: %.4f  acc: %.4f'\n",
    "                  % (step, train_auc, train_acc, eval_auc, eval_acc, test_auc, test_acc))\n",
    "\n",
    "            # top-K evaluation\n",
    "            if show_topk:\n",
    "                precision, recall, f1 = topk_eval(\n",
    "                    sess, model, user_list, train_record, test_record, item_set, k_list)\n",
    "                print('precision: ', end='')\n",
    "                logger.log('precision: ')\n",
    "                for i in precision:\n",
    "                    print('%.4f\\t' % i, end='')\n",
    "                    logger.log('%.4f\\t' % i)\n",
    "                print()\n",
    "                print('recall: ', end='')\n",
    "                logger.log('recall: ')\n",
    "                for i in recall:\n",
    "                    print('%.4f\\t' % i, end='')\n",
    "                    logger.log('%.4f\\t' % i)\n",
    "                print()\n",
    "                print('f1: ', end='')\n",
    "                logger.log('f1: ')\n",
    "                for i in f1:\n",
    "                    print('%.4f\\t' % i, end='')\n",
    "                    logger.log('%.4f\\t' % i)\n",
    "                print('\\n')\n",
    "            \n",
    "            saver.save(sess, session_log_path + \"models/epoch_{}\".format(step))\n",
    "\n",
    "\n",
    "def get_feed_dict_for_rs(model, data, start, end):\n",
    "    feed_dict = {model.user_indices: data[start:end, 0],\n",
    "                 model.item_indices: data[start:end, 1],\n",
    "                 model.labels: data[start:end, 2],\n",
    "                 model.head_indices: data[start:end, 1]}\n",
    "    return feed_dict\n",
    "\n",
    "\n",
    "def get_feed_dict_for_kge(model, kg, start, end):\n",
    "    feed_dict = {model.item_indices: kg[start:end, 0],\n",
    "                 model.head_indices: kg[start:end, 0],\n",
    "                 model.relation_indices: kg[start:end, 1],\n",
    "                 model.tail_indices: kg[start:end, 2]}\n",
    "    return feed_dict\n",
    "\n",
    "\n",
    "def topk_eval(sess, model, user_list, train_record, test_record, item_set, k_list):\n",
    "    precision_list = {k: [] for k in k_list}\n",
    "    recall_list = {k: [] for k in k_list}\n",
    "\n",
    "    for user in user_list:\n",
    "        test_item_list = list(item_set - train_record[user])\n",
    "        item_score_map = dict()\n",
    "        items, scores = model.get_scores(sess, {model.user_indices: [user] * len(test_item_list),\n",
    "                                                model.item_indices: test_item_list,\n",
    "                                                model.head_indices: test_item_list})\n",
    "        for item, score in zip(items, scores):\n",
    "            item_score_map[item] = score\n",
    "        item_score_pair_sorted = sorted(item_score_map.items(), key=lambda x: x[1], reverse=True)\n",
    "        item_sorted = [i[0] for i in item_score_pair_sorted]\n",
    "\n",
    "        for k in k_list:\n",
    "            hit_num = len(set(item_sorted[:k]) & test_record[user])\n",
    "            precision_list[k].append(hit_num / k)\n",
    "            recall_list[k].append(hit_num / len(test_record[user]))\n",
    "\n",
    "    precision = [np.mean(precision_list[k]) for k in k_list]\n",
    "    recall = [np.mean(recall_list[k]) for k in k_list]\n",
    "    f1 = [2 / (1 / precision[i] + 1 / recall[i]) for i in range(len(k_list))]\n",
    "\n",
    "    return precision, recall, f1\n",
    "\n",
    "\n",
    "def get_user_record(data, is_train):\n",
    "    user_history_dict = dict()\n",
    "    for interaction in data:\n",
    "        user = interaction[0]\n",
    "        item = interaction[1]\n",
    "        label = interaction[2]\n",
    "        if is_train or label == 1:\n",
    "            if user not in user_history_dict:\n",
    "                user_history_dict[user] = set()\n",
    "            user_history_dict[user].add(item)\n",
    "    return user_history_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../src/data_loader.py\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "def load_data(args):\n",
    "    n_user, n_item, train_data, eval_data, test_data = load_rating(args)\n",
    "    n_entity, n_relation, kg = load_kg(args)\n",
    "    print('data loaded.')\n",
    "\n",
    "    return n_user, n_item, n_entity, n_relation, train_data, eval_data, test_data, kg\n",
    "\n",
    "\n",
    "def load_rating(args):\n",
    "    print('reading rating file ...')\n",
    "\n",
    "    # reading rating file\n",
    "    rating_file = '../data/' + args.dataset + '/ratings_final'\n",
    "    #rating_file = '../data/' + 'intersect-14m' + '/ratings_final'\n",
    "    if os.path.exists(rating_file + '.npy'):\n",
    "        rating_np = np.load(rating_file + '.npy')\n",
    "    else:\n",
    "        rating_np = np.loadtxt(rating_file + '.txt', dtype=np.int32)\n",
    "        np.save(rating_file + '.npy', rating_np)\n",
    "\n",
    "    n_user = max(set(rating_np[:, 0])) + 1\n",
    "    n_item = max(set(rating_np[:, 1])) + 1\n",
    "    train_data, eval_data, test_data = dataset_split(rating_np)\n",
    "\n",
    "    return n_user, n_item, train_data, eval_data, test_data\n",
    "\n",
    "\n",
    "def dataset_split(rating_np):\n",
    "    print('splitting dataset ...')\n",
    "\n",
    "    # train:eval:test = 6:2:2\n",
    "    eval_ratio = 0.2\n",
    "    test_ratio = 0.2\n",
    "    n_ratings = rating_np.shape[0]\n",
    "\n",
    "    eval_indices = np.random.choice(list(range(n_ratings)), size=int(n_ratings * eval_ratio), replace=False)\n",
    "    left = set(range(n_ratings)) - set(eval_indices)\n",
    "    test_indices = np.random.choice(list(left), size=int(n_ratings * test_ratio), replace=False)\n",
    "    train_indices = list(left - set(test_indices))\n",
    "\n",
    "    train_data = rating_np[train_indices]\n",
    "    eval_data = rating_np[eval_indices]\n",
    "    test_data = rating_np[test_indices]\n",
    "\n",
    "    return train_data, eval_data, test_data\n",
    "\n",
    "\n",
    "def load_kg(args):\n",
    "    print('reading KG file ...')\n",
    "\n",
    "    # reading kg file\n",
    "    kg_file = '../data/' + args.dataset + '/kg_final'\n",
    "    #kg_file = '../data/' + 'intersect-14m' + '/kg_final'\n",
    "    if os.path.exists(kg_file + '.npy'):\n",
    "        kg = np.load(kg_file + '.npy')\n",
    "    else:\n",
    "        kg = np.loadtxt(kg_file + '.txt', dtype=np.int32)\n",
    "        np.save(kg_file + '.npy', kg)\n",
    "\n",
    "    n_entity = max(set(kg[:, 0]) | set(kg[:, 2]))+1\n",
    "    n_relation = max(set(kg[:, 1]))+1\n",
    "\n",
    "    return n_entity, n_relation, kg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.dataset = 'movie'\n",
    "        self.n_epoch = 20\n",
    "        self.dim = 8\n",
    "        self.L = 1\n",
    "        self.H = 1\n",
    "        self.batch_size = 4095\n",
    "        self.l2_weight = 1e-6\n",
    "        self.lr_rs = 0.000125\n",
    "        self.lr_kge = 0.000125\n",
    "        self.kge_interval = 3\n",
    "\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading rating file ...\n",
      "splitting dataset ...\n",
      "reading KG file ...\n",
      "data loaded.\n"
     ]
    }
   ],
   "source": [
    "data_info = load_data(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate the preprocesssing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_user = data_info[0]\n",
    "n_item = data_info[1]\n",
    "n_entity = data_info[2]\n",
    "n_relation = data_info[3]\n",
    "train_data = data_info[4]\n",
    "eval_data = data_info[5]\n",
    "test_data = data_info[6]\n",
    "kg = data_info[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6036"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_CODE = \"1564108661.9731\"\n",
    "CHOSEN_EPOCH = 19\n",
    "\n",
    "MODEL_PATH = \"../log/{}/models/epoch_{}\".format(TEST_CODE, CHOSEN_EPOCH)\n",
    "LOG_PATH = \"../log/{}/log.txt\".format(TEST_CODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0729 07:42:14.484763 139874676356928 deprecation.py:506] From /home/syahbimaa/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0729 07:42:14.603126 139874676356928 deprecation.py:506] From <ipython-input-3-a1149e15351b>:47: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0729 07:42:14.607710 139874676356928 deprecation.py:506] From /home/syahbimaa/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:180: calling expand_dims (from tensorflow.python.ops.array_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n",
      "W0729 07:42:14.657592 139874676356928 deprecation.py:323] From /home/syahbimaa/.local/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = MKR(args, n_user, n_item, n_entity, n_relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit GPU usage\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0729 07:42:16.139000 139874676356928 deprecation.py:323] From /home/syahbimaa/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    }
   ],
   "source": [
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "saver = tf.train.import_meta_graph(MODEL_PATH + \".meta\")\n",
    "saver.restore(sess, MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dictionary of positive ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 452264/452264 [00:01<00:00, 303895.79it/s]\n",
      "100%|██████████| 150754/150754 [00:00<00:00, 281757.02it/s]\n",
      "100%|██████████| 150754/150754 [00:00<00:00, 278494.86it/s]\n"
     ]
    }
   ],
   "source": [
    "truth_dict = {}\n",
    "for rating in tqdm(train_data):\n",
    "    user_id, movie_id, score = rating\n",
    "    \n",
    "    if user_id not in truth_dict:\n",
    "        truth_dict[user_id] = []\n",
    "    \n",
    "    if score == 1:\n",
    "        truth_dict[user_id].append(movie_id)\n",
    "        \n",
    "for rating in tqdm(test_data):\n",
    "    user_id, movie_id, score = rating\n",
    "    \n",
    "    if user_id not in truth_dict:\n",
    "        truth_dict[user_id] = []\n",
    "    \n",
    "    if score == 1:\n",
    "        truth_dict[user_id].append(movie_id)\n",
    "        \n",
    "for rating in tqdm(eval_data):\n",
    "    user_id, movie_id, score = rating\n",
    "    \n",
    "    if user_id not in truth_dict:\n",
    "        truth_dict[user_id] = []\n",
    "    \n",
    "    if score == 1:\n",
    "        truth_dict[user_id].append(movie_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the frequency of user who liked n movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "ns = []\n",
    "for key in truth_dict:\n",
    "    n = len(truth_dict[key])\n",
    "    ns.append(n)\n",
    "\n",
    "ns = Counter(ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({25: 76,\n",
       "         52: 48,\n",
       "         26: 92,\n",
       "         14: 125,\n",
       "         57: 53,\n",
       "         17: 123,\n",
       "         53: 28,\n",
       "         198: 7,\n",
       "         50: 38,\n",
       "         11: 132,\n",
       "         30: 63,\n",
       "         68: 45,\n",
       "         108: 18,\n",
       "         114: 15,\n",
       "         90: 16,\n",
       "         4: 22,\n",
       "         80: 32,\n",
       "         83: 19,\n",
       "         75: 30,\n",
       "         37: 50,\n",
       "         63: 36,\n",
       "         34: 55,\n",
       "         44: 40,\n",
       "         36: 71,\n",
       "         18: 88,\n",
       "         39: 56,\n",
       "         116: 14,\n",
       "         77: 31,\n",
       "         197: 4,\n",
       "         21: 98,\n",
       "         20: 104,\n",
       "         35: 57,\n",
       "         8: 89,\n",
       "         99: 16,\n",
       "         15: 133,\n",
       "         81: 20,\n",
       "         60: 19,\n",
       "         12: 147,\n",
       "         97: 20,\n",
       "         10: 140,\n",
       "         22: 82,\n",
       "         332: 2,\n",
       "         208: 4,\n",
       "         65: 34,\n",
       "         5: 29,\n",
       "         156: 5,\n",
       "         69: 32,\n",
       "         43: 49,\n",
       "         13: 127,\n",
       "         88: 14,\n",
       "         92: 21,\n",
       "         49: 46,\n",
       "         9: 99,\n",
       "         56: 36,\n",
       "         41: 43,\n",
       "         16: 134,\n",
       "         28: 68,\n",
       "         29: 74,\n",
       "         95: 21,\n",
       "         59: 41,\n",
       "         32: 74,\n",
       "         76: 29,\n",
       "         31: 56,\n",
       "         67: 30,\n",
       "         33: 55,\n",
       "         46: 48,\n",
       "         45: 33,\n",
       "         27: 76,\n",
       "         40: 51,\n",
       "         131: 10,\n",
       "         89: 16,\n",
       "         24: 79,\n",
       "         42: 55,\n",
       "         170: 7,\n",
       "         72: 26,\n",
       "         106: 15,\n",
       "         23: 95,\n",
       "         176: 3,\n",
       "         243: 4,\n",
       "         294: 1,\n",
       "         140: 1,\n",
       "         189: 6,\n",
       "         184: 2,\n",
       "         55: 34,\n",
       "         145: 6,\n",
       "         229: 8,\n",
       "         7: 78,\n",
       "         244: 1,\n",
       "         164: 9,\n",
       "         133: 10,\n",
       "         62: 37,\n",
       "         256: 3,\n",
       "         148: 11,\n",
       "         94: 23,\n",
       "         360: 1,\n",
       "         166: 7,\n",
       "         112: 13,\n",
       "         186: 8,\n",
       "         168: 4,\n",
       "         71: 25,\n",
       "         19: 92,\n",
       "         51: 51,\n",
       "         218: 7,\n",
       "         6: 51,\n",
       "         47: 41,\n",
       "         82: 22,\n",
       "         200: 3,\n",
       "         98: 21,\n",
       "         58: 34,\n",
       "         226: 2,\n",
       "         61: 32,\n",
       "         103: 21,\n",
       "         48: 50,\n",
       "         142: 11,\n",
       "         136: 5,\n",
       "         85: 19,\n",
       "         70: 24,\n",
       "         154: 9,\n",
       "         199: 2,\n",
       "         79: 19,\n",
       "         78: 28,\n",
       "         74: 22,\n",
       "         117: 19,\n",
       "         126: 13,\n",
       "         167: 11,\n",
       "         183: 7,\n",
       "         104: 11,\n",
       "         84: 18,\n",
       "         101: 21,\n",
       "         211: 3,\n",
       "         259: 1,\n",
       "         155: 11,\n",
       "         149: 7,\n",
       "         178: 7,\n",
       "         304: 2,\n",
       "         159: 6,\n",
       "         119: 9,\n",
       "         137: 11,\n",
       "         66: 28,\n",
       "         93: 15,\n",
       "         182: 9,\n",
       "         38: 57,\n",
       "         123: 9,\n",
       "         152: 9,\n",
       "         175: 7,\n",
       "         263: 2,\n",
       "         54: 31,\n",
       "         127: 14,\n",
       "         487: 1,\n",
       "         73: 21,\n",
       "         228: 5,\n",
       "         201: 6,\n",
       "         120: 18,\n",
       "         173: 7,\n",
       "         111: 15,\n",
       "         110: 10,\n",
       "         146: 9,\n",
       "         87: 27,\n",
       "         216: 3,\n",
       "         129: 10,\n",
       "         139: 11,\n",
       "         400: 2,\n",
       "         185: 5,\n",
       "         64: 31,\n",
       "         328: 2,\n",
       "         469: 1,\n",
       "         115: 13,\n",
       "         102: 19,\n",
       "         242: 3,\n",
       "         91: 20,\n",
       "         124: 11,\n",
       "         105: 9,\n",
       "         141: 9,\n",
       "         125: 10,\n",
       "         191: 6,\n",
       "         147: 8,\n",
       "         202: 1,\n",
       "         96: 10,\n",
       "         399: 1,\n",
       "         107: 11,\n",
       "         305: 1,\n",
       "         306: 2,\n",
       "         194: 3,\n",
       "         217: 3,\n",
       "         286: 4,\n",
       "         174: 6,\n",
       "         151: 9,\n",
       "         122: 17,\n",
       "         252: 1,\n",
       "         207: 4,\n",
       "         118: 9,\n",
       "         3: 17,\n",
       "         388: 1,\n",
       "         135: 2,\n",
       "         192: 5,\n",
       "         204: 2,\n",
       "         317: 2,\n",
       "         100: 17,\n",
       "         241: 1,\n",
       "         179: 3,\n",
       "         134: 8,\n",
       "         163: 11,\n",
       "         187: 4,\n",
       "         153: 6,\n",
       "         130: 6,\n",
       "         188: 4,\n",
       "         258: 3,\n",
       "         150: 15,\n",
       "         490: 2,\n",
       "         251: 3,\n",
       "         157: 5,\n",
       "         327: 2,\n",
       "         222: 2,\n",
       "         160: 8,\n",
       "         169: 9,\n",
       "         371: 1,\n",
       "         337: 1,\n",
       "         335: 1,\n",
       "         161: 5,\n",
       "         143: 9,\n",
       "         86: 20,\n",
       "         205: 5,\n",
       "         180: 5,\n",
       "         311: 1,\n",
       "         113: 14,\n",
       "         230: 5,\n",
       "         181: 4,\n",
       "         234: 5,\n",
       "         267: 3,\n",
       "         227: 1,\n",
       "         522: 1,\n",
       "         224: 2,\n",
       "         255: 4,\n",
       "         353: 1,\n",
       "         128: 8,\n",
       "         210: 1,\n",
       "         206: 2,\n",
       "         248: 2,\n",
       "         158: 4,\n",
       "         283: 3,\n",
       "         461: 1,\n",
       "         235: 2,\n",
       "         348: 1,\n",
       "         257: 4,\n",
       "         132: 5,\n",
       "         144: 10,\n",
       "         109: 15,\n",
       "         273: 1,\n",
       "         195: 5,\n",
       "         281: 2,\n",
       "         321: 1,\n",
       "         232: 2,\n",
       "         276: 2,\n",
       "         268: 1,\n",
       "         284: 2,\n",
       "         702: 1,\n",
       "         177: 4,\n",
       "         449: 1,\n",
       "         193: 6,\n",
       "         270: 1,\n",
       "         291: 1,\n",
       "         309: 2,\n",
       "         162: 5,\n",
       "         223: 1,\n",
       "         341: 2,\n",
       "         385: 1,\n",
       "         225: 2,\n",
       "         265: 2,\n",
       "         250: 3,\n",
       "         289: 3,\n",
       "         307: 2,\n",
       "         272: 3,\n",
       "         336: 3,\n",
       "         287: 1,\n",
       "         221: 3,\n",
       "         418: 1,\n",
       "         278: 1,\n",
       "         271: 2,\n",
       "         261: 2,\n",
       "         314: 2,\n",
       "         275: 1,\n",
       "         121: 6,\n",
       "         138: 13,\n",
       "         209: 5,\n",
       "         165: 3,\n",
       "         362: 1,\n",
       "         236: 3,\n",
       "         215: 3,\n",
       "         302: 1,\n",
       "         2: 3,\n",
       "         297: 2,\n",
       "         376: 1,\n",
       "         231: 2,\n",
       "         246: 3,\n",
       "         238: 2,\n",
       "         172: 6,\n",
       "         339: 2,\n",
       "         239: 1,\n",
       "         526: 1,\n",
       "         254: 1,\n",
       "         410: 1,\n",
       "         171: 6,\n",
       "         495: 1,\n",
       "         354: 1,\n",
       "         431: 1,\n",
       "         196: 4,\n",
       "         506: 1,\n",
       "         310: 1,\n",
       "         538: 1,\n",
       "         212: 2,\n",
       "         300: 3,\n",
       "         290: 1,\n",
       "         280: 3,\n",
       "         372: 1,\n",
       "         320: 1,\n",
       "         220: 1,\n",
       "         358: 2,\n",
       "         738: 1,\n",
       "         253: 2,\n",
       "         900: 1,\n",
       "         426: 1,\n",
       "         266: 1,\n",
       "         308: 2,\n",
       "         190: 2,\n",
       "         496: 1,\n",
       "         357: 1,\n",
       "         249: 1,\n",
       "         333: 1,\n",
       "         323: 1,\n",
       "         237: 1,\n",
       "         296: 2,\n",
       "         351: 1,\n",
       "         269: 1,\n",
       "         422: 1,\n",
       "         349: 1,\n",
       "         279: 1,\n",
       "         345: 1,\n",
       "         240: 1,\n",
       "         282: 1,\n",
       "         247: 1,\n",
       "         203: 1,\n",
       "         368: 1,\n",
       "         519: 1,\n",
       "         219: 1})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nscum = {}\n",
    "last = 0\n",
    "for k in sorted(ns):\n",
    "    nscum[k] = ns[k] + last\n",
    "    last = nscum[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f35f1d9dcf8>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# cummulative plot\n",
    "plt.figure(figsize=(20,14))\n",
    "plt.plot(list(nscum.keys())[:50], list(nscum.values())[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create set of user and movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_set = set(truth_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6036/6036 [00:00<00:00, 77491.37it/s]\n"
     ]
    }
   ],
   "source": [
    "movie_set = set()\n",
    "for user in tqdm(user_set) :\n",
    "    for movie in truth_dict[user] :\n",
    "        movie_set.add(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 150,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 200,\n",
       " 201,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 208,\n",
       " 209,\n",
       " 210,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 218,\n",
       " 219,\n",
       " 220,\n",
       " 221,\n",
       " 222,\n",
       " 223,\n",
       " 224,\n",
       " 225,\n",
       " 226,\n",
       " 227,\n",
       " 228,\n",
       " 229,\n",
       " 230,\n",
       " 231,\n",
       " 232,\n",
       " 233,\n",
       " 234,\n",
       " 235,\n",
       " 236,\n",
       " 237,\n",
       " 238,\n",
       " 239,\n",
       " 240,\n",
       " 241,\n",
       " 242,\n",
       " 243,\n",
       " 244,\n",
       " 245,\n",
       " 246,\n",
       " 247,\n",
       " 248,\n",
       " 249,\n",
       " 250,\n",
       " 251,\n",
       " 252,\n",
       " 253,\n",
       " 254,\n",
       " 255,\n",
       " 256,\n",
       " 257,\n",
       " 258,\n",
       " 259,\n",
       " 260,\n",
       " 261,\n",
       " 262,\n",
       " 263,\n",
       " 264,\n",
       " 265,\n",
       " 266,\n",
       " 267,\n",
       " 268,\n",
       " 269,\n",
       " 270,\n",
       " 271,\n",
       " 272,\n",
       " 273,\n",
       " 274,\n",
       " 275,\n",
       " 276,\n",
       " 277,\n",
       " 278,\n",
       " 279,\n",
       " 280,\n",
       " 281,\n",
       " 282,\n",
       " 283,\n",
       " 284,\n",
       " 285,\n",
       " 286,\n",
       " 287,\n",
       " 288,\n",
       " 289,\n",
       " 290,\n",
       " 291,\n",
       " 292,\n",
       " 293,\n",
       " 294,\n",
       " 295,\n",
       " 296,\n",
       " 297,\n",
       " 298,\n",
       " 299,\n",
       " 300,\n",
       " 301,\n",
       " 302,\n",
       " 303,\n",
       " 304,\n",
       " 305,\n",
       " 306,\n",
       " 307,\n",
       " 308,\n",
       " 309,\n",
       " 310,\n",
       " 311,\n",
       " 312,\n",
       " 313,\n",
       " 314,\n",
       " 315,\n",
       " 316,\n",
       " 317,\n",
       " 318,\n",
       " 319,\n",
       " 320,\n",
       " 321,\n",
       " 322,\n",
       " 323,\n",
       " 324,\n",
       " 325,\n",
       " 326,\n",
       " 327,\n",
       " 328,\n",
       " 329,\n",
       " 330,\n",
       " 331,\n",
       " 332,\n",
       " 333,\n",
       " 334,\n",
       " 335,\n",
       " 336,\n",
       " 337,\n",
       " 338,\n",
       " 339,\n",
       " 340,\n",
       " 341,\n",
       " 342,\n",
       " 343,\n",
       " 344,\n",
       " 345,\n",
       " 346,\n",
       " 347,\n",
       " 348,\n",
       " 349,\n",
       " 350,\n",
       " 351,\n",
       " 352,\n",
       " 353,\n",
       " 354,\n",
       " 355,\n",
       " 356,\n",
       " 357,\n",
       " 358,\n",
       " 359,\n",
       " 360,\n",
       " 361,\n",
       " 362,\n",
       " 363,\n",
       " 364,\n",
       " 365,\n",
       " 366,\n",
       " 367,\n",
       " 368,\n",
       " 369,\n",
       " 370,\n",
       " 371,\n",
       " 372,\n",
       " 374,\n",
       " 375,\n",
       " 376,\n",
       " 377,\n",
       " 379,\n",
       " 380,\n",
       " 381,\n",
       " 382,\n",
       " 383,\n",
       " 384,\n",
       " 385,\n",
       " 386,\n",
       " 387,\n",
       " 388,\n",
       " 389,\n",
       " 390,\n",
       " 391,\n",
       " 392,\n",
       " 393,\n",
       " 394,\n",
       " 395,\n",
       " 396,\n",
       " 397,\n",
       " 399,\n",
       " 400,\n",
       " 401,\n",
       " 402,\n",
       " 406,\n",
       " 407,\n",
       " 408,\n",
       " 409,\n",
       " 411,\n",
       " 412,\n",
       " 415,\n",
       " 416,\n",
       " 417,\n",
       " 418,\n",
       " 419,\n",
       " 420,\n",
       " 421,\n",
       " 422,\n",
       " 423,\n",
       " 424,\n",
       " 425,\n",
       " 426,\n",
       " 427,\n",
       " 428,\n",
       " 429,\n",
       " 430,\n",
       " 431,\n",
       " 432,\n",
       " 433,\n",
       " 434,\n",
       " 436,\n",
       " 437,\n",
       " 438,\n",
       " 439,\n",
       " 440,\n",
       " 441,\n",
       " 442,\n",
       " 443,\n",
       " 444,\n",
       " 445,\n",
       " 446,\n",
       " 447,\n",
       " 448,\n",
       " 449,\n",
       " 450,\n",
       " 451,\n",
       " 453,\n",
       " 454,\n",
       " 455,\n",
       " 456,\n",
       " 457,\n",
       " 459,\n",
       " 460,\n",
       " 461,\n",
       " 462,\n",
       " 463,\n",
       " 464,\n",
       " 465,\n",
       " 466,\n",
       " 467,\n",
       " 468,\n",
       " 469,\n",
       " 471,\n",
       " 472,\n",
       " 473,\n",
       " 474,\n",
       " 475,\n",
       " 476,\n",
       " 477,\n",
       " 478,\n",
       " 479,\n",
       " 480,\n",
       " 482,\n",
       " 483,\n",
       " 484,\n",
       " 485,\n",
       " 486,\n",
       " 487,\n",
       " 488,\n",
       " 489,\n",
       " 490,\n",
       " 491,\n",
       " 492,\n",
       " 494,\n",
       " 495,\n",
       " 496,\n",
       " 498,\n",
       " 499,\n",
       " 500,\n",
       " 501,\n",
       " 502,\n",
       " 504,\n",
       " 505,\n",
       " 508,\n",
       " 509,\n",
       " 510,\n",
       " 511,\n",
       " 512,\n",
       " 513,\n",
       " 514,\n",
       " 515,\n",
       " 516,\n",
       " 517,\n",
       " 520,\n",
       " 521,\n",
       " 522,\n",
       " 523,\n",
       " 524,\n",
       " 525,\n",
       " 526,\n",
       " 528,\n",
       " 529,\n",
       " 531,\n",
       " 532,\n",
       " 534,\n",
       " 535,\n",
       " 536,\n",
       " 537,\n",
       " 538,\n",
       " 539,\n",
       " 540,\n",
       " 541,\n",
       " 542,\n",
       " 543,\n",
       " 544,\n",
       " 545,\n",
       " 546,\n",
       " 547,\n",
       " 548,\n",
       " 549,\n",
       " 550,\n",
       " 551,\n",
       " 552,\n",
       " 553,\n",
       " 554,\n",
       " 555,\n",
       " 556,\n",
       " 557,\n",
       " 558,\n",
       " 559,\n",
       " 560,\n",
       " 561,\n",
       " 562,\n",
       " 563,\n",
       " 564,\n",
       " 565,\n",
       " 566,\n",
       " 567,\n",
       " 569,\n",
       " 570,\n",
       " 571,\n",
       " 572,\n",
       " 573,\n",
       " 574,\n",
       " 575,\n",
       " 576,\n",
       " 577,\n",
       " 578,\n",
       " 579,\n",
       " 580,\n",
       " 581,\n",
       " 582,\n",
       " 583,\n",
       " 584,\n",
       " 585,\n",
       " 586,\n",
       " 587,\n",
       " 588,\n",
       " 589,\n",
       " 590,\n",
       " 591,\n",
       " 592,\n",
       " 593,\n",
       " 594,\n",
       " 595,\n",
       " 596,\n",
       " 597,\n",
       " 598,\n",
       " 599,\n",
       " 600,\n",
       " 601,\n",
       " 602,\n",
       " 603,\n",
       " 604,\n",
       " 605,\n",
       " 606,\n",
       " 607,\n",
       " 608,\n",
       " 609,\n",
       " 610,\n",
       " 611,\n",
       " 612,\n",
       " 613,\n",
       " 614,\n",
       " 615,\n",
       " 617,\n",
       " 618,\n",
       " 619,\n",
       " 620,\n",
       " 622,\n",
       " 623,\n",
       " 624,\n",
       " 625,\n",
       " 626,\n",
       " 627,\n",
       " 628,\n",
       " 629,\n",
       " 630,\n",
       " 631,\n",
       " 632,\n",
       " 633,\n",
       " 634,\n",
       " 635,\n",
       " 636,\n",
       " 638,\n",
       " 639,\n",
       " 640,\n",
       " 641,\n",
       " 642,\n",
       " 643,\n",
       " 644,\n",
       " 645,\n",
       " 646,\n",
       " 647,\n",
       " 648,\n",
       " 649,\n",
       " 650,\n",
       " 651,\n",
       " 652,\n",
       " 653,\n",
       " 654,\n",
       " 657,\n",
       " 658,\n",
       " 659,\n",
       " 660,\n",
       " 663,\n",
       " 664,\n",
       " 665,\n",
       " 666,\n",
       " 667,\n",
       " 668,\n",
       " 669,\n",
       " 670,\n",
       " 671,\n",
       " 672,\n",
       " 674,\n",
       " 675,\n",
       " 677,\n",
       " 678,\n",
       " 679,\n",
       " 680,\n",
       " 681,\n",
       " 682,\n",
       " 683,\n",
       " 684,\n",
       " 685,\n",
       " 686,\n",
       " 687,\n",
       " 688,\n",
       " 689,\n",
       " 690,\n",
       " 691,\n",
       " 692,\n",
       " 693,\n",
       " 694,\n",
       " 695,\n",
       " 696,\n",
       " 697,\n",
       " 698,\n",
       " 699,\n",
       " 700,\n",
       " 701,\n",
       " 702,\n",
       " 703,\n",
       " 704,\n",
       " 705,\n",
       " 706,\n",
       " 707,\n",
       " 708,\n",
       " 709,\n",
       " 710,\n",
       " 711,\n",
       " 712,\n",
       " 713,\n",
       " 714,\n",
       " 715,\n",
       " 716,\n",
       " 717,\n",
       " 718,\n",
       " 719,\n",
       " 720,\n",
       " 721,\n",
       " 722,\n",
       " 723,\n",
       " 724,\n",
       " 725,\n",
       " 726,\n",
       " 727,\n",
       " 728,\n",
       " 729,\n",
       " 730,\n",
       " 731,\n",
       " 732,\n",
       " 733,\n",
       " 734,\n",
       " 735,\n",
       " 736,\n",
       " 737,\n",
       " 738,\n",
       " 739,\n",
       " 740,\n",
       " 741,\n",
       " 742,\n",
       " 743,\n",
       " 744,\n",
       " 745,\n",
       " 746,\n",
       " 747,\n",
       " 748,\n",
       " 749,\n",
       " 750,\n",
       " 751,\n",
       " 752,\n",
       " 753,\n",
       " 754,\n",
       " 755,\n",
       " 756,\n",
       " 757,\n",
       " 758,\n",
       " 759,\n",
       " 760,\n",
       " 761,\n",
       " 762,\n",
       " 763,\n",
       " 765,\n",
       " 766,\n",
       " 768,\n",
       " 769,\n",
       " 770,\n",
       " 771,\n",
       " 772,\n",
       " 773,\n",
       " 774,\n",
       " 775,\n",
       " 776,\n",
       " 777,\n",
       " 778,\n",
       " 779,\n",
       " 780,\n",
       " 781,\n",
       " 782,\n",
       " 783,\n",
       " 784,\n",
       " 785,\n",
       " 786,\n",
       " 787,\n",
       " 788,\n",
       " 789,\n",
       " 790,\n",
       " 791,\n",
       " 792,\n",
       " 793,\n",
       " 794,\n",
       " 795,\n",
       " 796,\n",
       " 797,\n",
       " 799,\n",
       " 801,\n",
       " 802,\n",
       " 803,\n",
       " 804,\n",
       " 805,\n",
       " 806,\n",
       " 807,\n",
       " 808,\n",
       " 809,\n",
       " 810,\n",
       " 811,\n",
       " 812,\n",
       " 813,\n",
       " 814,\n",
       " 815,\n",
       " 816,\n",
       " 817,\n",
       " 818,\n",
       " 819,\n",
       " 820,\n",
       " 821,\n",
       " 822,\n",
       " 823,\n",
       " 824,\n",
       " 825,\n",
       " 826,\n",
       " 827,\n",
       " 828,\n",
       " 829,\n",
       " 830,\n",
       " 831,\n",
       " 832,\n",
       " 833,\n",
       " 834,\n",
       " 835,\n",
       " 836,\n",
       " 837,\n",
       " 838,\n",
       " 839,\n",
       " 840,\n",
       " 841,\n",
       " 842,\n",
       " 843,\n",
       " 844,\n",
       " 845,\n",
       " 846,\n",
       " 847,\n",
       " 848,\n",
       " 849,\n",
       " 850,\n",
       " 851,\n",
       " 852,\n",
       " 853,\n",
       " 854,\n",
       " 855,\n",
       " 856,\n",
       " 857,\n",
       " 858,\n",
       " 859,\n",
       " 860,\n",
       " 861,\n",
       " 862,\n",
       " 863,\n",
       " 864,\n",
       " 865,\n",
       " 866,\n",
       " 867,\n",
       " 868,\n",
       " 870,\n",
       " 871,\n",
       " 872,\n",
       " 873,\n",
       " 874,\n",
       " 875,\n",
       " 876,\n",
       " 877,\n",
       " 878,\n",
       " 879,\n",
       " 880,\n",
       " 881,\n",
       " 882,\n",
       " 884,\n",
       " 885,\n",
       " 886,\n",
       " 887,\n",
       " 888,\n",
       " 889,\n",
       " 890,\n",
       " 891,\n",
       " 892,\n",
       " 893,\n",
       " 894,\n",
       " 896,\n",
       " 897,\n",
       " 898,\n",
       " 899,\n",
       " 900,\n",
       " 901,\n",
       " 902,\n",
       " 903,\n",
       " 905,\n",
       " 906,\n",
       " 907,\n",
       " 908,\n",
       " 909,\n",
       " 910,\n",
       " 911,\n",
       " 912,\n",
       " 913,\n",
       " 914,\n",
       " 915,\n",
       " 916,\n",
       " 917,\n",
       " 918,\n",
       " 919,\n",
       " 920,\n",
       " 921,\n",
       " 922,\n",
       " 923,\n",
       " 924,\n",
       " 925,\n",
       " 927,\n",
       " 928,\n",
       " 929,\n",
       " 930,\n",
       " 931,\n",
       " 932,\n",
       " 933,\n",
       " 934,\n",
       " 935,\n",
       " 936,\n",
       " 937,\n",
       " 938,\n",
       " 939,\n",
       " 940,\n",
       " 941,\n",
       " 942,\n",
       " 943,\n",
       " 944,\n",
       " 945,\n",
       " 946,\n",
       " 947,\n",
       " 948,\n",
       " 949,\n",
       " 950,\n",
       " 951,\n",
       " 952,\n",
       " 953,\n",
       " 954,\n",
       " 955,\n",
       " 956,\n",
       " 957,\n",
       " 958,\n",
       " 959,\n",
       " 960,\n",
       " 961,\n",
       " 962,\n",
       " 963,\n",
       " 964,\n",
       " 965,\n",
       " 966,\n",
       " 967,\n",
       " 968,\n",
       " 969,\n",
       " 970,\n",
       " 971,\n",
       " 972,\n",
       " 973,\n",
       " 974,\n",
       " 975,\n",
       " 977,\n",
       " 978,\n",
       " 980,\n",
       " 981,\n",
       " 982,\n",
       " 983,\n",
       " 984,\n",
       " 985,\n",
       " 986,\n",
       " 987,\n",
       " 988,\n",
       " 989,\n",
       " 990,\n",
       " 991,\n",
       " 992,\n",
       " 993,\n",
       " 994,\n",
       " 995,\n",
       " 996,\n",
       " 997,\n",
       " 998,\n",
       " 999,\n",
       " 1000,\n",
       " 1001,\n",
       " 1002,\n",
       " 1003,\n",
       " 1004,\n",
       " 1005,\n",
       " 1006,\n",
       " 1007,\n",
       " 1008,\n",
       " 1009,\n",
       " 1010,\n",
       " 1011,\n",
       " 1012,\n",
       " 1013,\n",
       " 1014,\n",
       " 1015,\n",
       " 1016,\n",
       " 1017,\n",
       " 1018,\n",
       " 1019,\n",
       " 1020,\n",
       " 1021,\n",
       " 1022,\n",
       " 1023,\n",
       " 1024,\n",
       " 1025,\n",
       " 1026,\n",
       " 1027,\n",
       " 1028,\n",
       " 1029,\n",
       " 1030,\n",
       " 1031,\n",
       " 1032,\n",
       " 1033,\n",
       " 1035,\n",
       " 1036,\n",
       " 1037,\n",
       " 1038,\n",
       " 1040,\n",
       " 1041,\n",
       " 1042,\n",
       " 1043,\n",
       " 1044,\n",
       " 1045,\n",
       " 1046,\n",
       " 1047,\n",
       " 1048,\n",
       " 1049,\n",
       " 1050,\n",
       " 1051,\n",
       " 1052,\n",
       " 1053,\n",
       " ...}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_score_map = dict()\n",
    "items, scores = model.get_scores(sess, {model.user_indices: [1] * len(movie_set),\n",
    "                                        model.item_indices: list(movie_set),\n",
    "                                        model.head_indices: list(movie_set)})\n",
    "for item, score in zip(items, scores):\n",
    "        item_score_map[item] = score\n",
    "\n",
    "item_score_pair_sorted = sorted(item_score_map.items(), key=lambda x: x[1], reverse=True)\n",
    "item_sorted = [i[0] for i in item_score_pair_sorted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[694,\n",
       " 1381,\n",
       " 333,\n",
       " 759,\n",
       " 514,\n",
       " 1159,\n",
       " 371,\n",
       " 162,\n",
       " 636,\n",
       " 0,\n",
       " 704,\n",
       " 921,\n",
       " 1595,\n",
       " 734,\n",
       " 726,\n",
       " 696,\n",
       " 710,\n",
       " 184,\n",
       " 1483,\n",
       " 201,\n",
       " 736,\n",
       " 721,\n",
       " 658,\n",
       " 762,\n",
       " 695,\n",
       " 1962,\n",
       " 374,\n",
       " 7,\n",
       " 31,\n",
       " 1139,\n",
       " 564,\n",
       " 1613,\n",
       " 301,\n",
       " 740,\n",
       " 750,\n",
       " 693,\n",
       " 341,\n",
       " 974,\n",
       " 2035,\n",
       " 226,\n",
       " 372,\n",
       " 1780,\n",
       " 1998,\n",
       " 1845,\n",
       " 542,\n",
       " 684,\n",
       " 88,\n",
       " 2001,\n",
       " 807,\n",
       " 1994,\n",
       " 1349,\n",
       " 724,\n",
       " 1389,\n",
       " 2216,\n",
       " 1617,\n",
       " 1808,\n",
       " 701,\n",
       " 16,\n",
       " 2093,\n",
       " 227,\n",
       " 1117,\n",
       " 544,\n",
       " 26,\n",
       " 1512,\n",
       " 536,\n",
       " 801,\n",
       " 339,\n",
       " 716,\n",
       " 1261,\n",
       " 623,\n",
       " 709,\n",
       " 2164,\n",
       " 1732,\n",
       " 1700,\n",
       " 1701,\n",
       " 2087,\n",
       " 408,\n",
       " 548,\n",
       " 732,\n",
       " 723,\n",
       " 1684,\n",
       " 2033,\n",
       " 1775,\n",
       " 1111,\n",
       " 596,\n",
       " 1891,\n",
       " 717,\n",
       " 2094,\n",
       " 664,\n",
       " 1622,\n",
       " 1429,\n",
       " 863,\n",
       " 1702,\n",
       " 12,\n",
       " 1892,\n",
       " 2075,\n",
       " 1546,\n",
       " 1698,\n",
       " 1113,\n",
       " 698,\n",
       " 782,\n",
       " 2153,\n",
       " 2023,\n",
       " 808,\n",
       " 1739,\n",
       " 1825,\n",
       " 537,\n",
       " 221,\n",
       " 751,\n",
       " 983,\n",
       " 1826,\n",
       " 754,\n",
       " 375,\n",
       " 1102,\n",
       " 593,\n",
       " 2296,\n",
       " 97,\n",
       " 629,\n",
       " 1799,\n",
       " 1108,\n",
       " 240,\n",
       " 1961,\n",
       " 738,\n",
       " 1214,\n",
       " 1445,\n",
       " 718,\n",
       " 1889,\n",
       " 1964,\n",
       " 934,\n",
       " 559,\n",
       " 1654,\n",
       " 757,\n",
       " 543,\n",
       " 463,\n",
       " 733,\n",
       " 1795,\n",
       " 1846,\n",
       " 713,\n",
       " 1145,\n",
       " 1960,\n",
       " 1294,\n",
       " 793,\n",
       " 1251,\n",
       " 539,\n",
       " 1346,\n",
       " 1854,\n",
       " 1347,\n",
       " 2190,\n",
       " 1967,\n",
       " 1105,\n",
       " 2074,\n",
       " 2060,\n",
       " 1320,\n",
       " 702,\n",
       " 2189,\n",
       " 232,\n",
       " 459,\n",
       " 631,\n",
       " 1659,\n",
       " 2324,\n",
       " 627,\n",
       " 633,\n",
       " 2131,\n",
       " 63,\n",
       " 547,\n",
       " 1280,\n",
       " 700,\n",
       " 1109,\n",
       " 1551,\n",
       " 2034,\n",
       " 1703,\n",
       " 1963,\n",
       " 879,\n",
       " 136,\n",
       " 741,\n",
       " 151,\n",
       " 1140,\n",
       " 711,\n",
       " 624,\n",
       " 512,\n",
       " 1863,\n",
       " 323,\n",
       " 1601,\n",
       " 1561,\n",
       " 730,\n",
       " 747,\n",
       " 557,\n",
       " 1103,\n",
       " 1537,\n",
       " 1686,\n",
       " 873,\n",
       " 1301,\n",
       " 165,\n",
       " 1351,\n",
       " 2273,\n",
       " 1786,\n",
       " 349,\n",
       " 1986,\n",
       " 1091,\n",
       " 689,\n",
       " 1798,\n",
       " 1805,\n",
       " 949,\n",
       " 2061,\n",
       " 959,\n",
       " 1378,\n",
       " 1193,\n",
       " 781,\n",
       " 686,\n",
       " 1283,\n",
       " 1210,\n",
       " 1844,\n",
       " 1781,\n",
       " 2243,\n",
       " 1835,\n",
       " 1182,\n",
       " 1777,\n",
       " 1404,\n",
       " 1582,\n",
       " 1400,\n",
       " 961,\n",
       " 1833,\n",
       " 902,\n",
       " 1802,\n",
       " 2321,\n",
       " 1377,\n",
       " 2253,\n",
       " 1707,\n",
       " 1112,\n",
       " 2173,\n",
       " 2177,\n",
       " 1796,\n",
       " 1110,\n",
       " 1446,\n",
       " 558,\n",
       " 788,\n",
       " 1579,\n",
       " 2218,\n",
       " 83,\n",
       " 1188,\n",
       " 1925,\n",
       " 737,\n",
       " 715,\n",
       " 2004,\n",
       " 426,\n",
       " 2312,\n",
       " 1238,\n",
       " 727,\n",
       " 1536,\n",
       " 540,\n",
       " 628,\n",
       " 678,\n",
       " 1794,\n",
       " 1762,\n",
       " 2208,\n",
       " 1100,\n",
       " 969,\n",
       " 1311,\n",
       " 1773,\n",
       " 1141,\n",
       " 447,\n",
       " 1571,\n",
       " 2255,\n",
       " 1359,\n",
       " 1153,\n",
       " 796,\n",
       " 1610,\n",
       " 1548,\n",
       " 186,\n",
       " 38,\n",
       " 682,\n",
       " 602,\n",
       " 1655,\n",
       " 1850,\n",
       " 2064,\n",
       " 1460,\n",
       " 36,\n",
       " 334,\n",
       " 551,\n",
       " 839,\n",
       " 987,\n",
       " 1993,\n",
       " 220,\n",
       " 1233,\n",
       " 632,\n",
       " 2223,\n",
       " 2024,\n",
       " 1385,\n",
       " 318,\n",
       " 1136,\n",
       " 2257,\n",
       " 990,\n",
       " 2040,\n",
       " 2267,\n",
       " 164,\n",
       " 1712,\n",
       " 712,\n",
       " 272,\n",
       " 394,\n",
       " 2112,\n",
       " 1325,\n",
       " 753,\n",
       " 1635,\n",
       " 2132,\n",
       " 1006,\n",
       " 1156,\n",
       " 1946,\n",
       " 1966,\n",
       " 993,\n",
       " 1484,\n",
       " 1314,\n",
       " 2211,\n",
       " 1713,\n",
       " 1933,\n",
       " 941,\n",
       " 1063,\n",
       " 199,\n",
       " 2204,\n",
       " 2063,\n",
       " 707,\n",
       " 1768,\n",
       " 834,\n",
       " 1426,\n",
       " 2167,\n",
       " 407,\n",
       " 2335,\n",
       " 200,\n",
       " 758,\n",
       " 1149,\n",
       " 2176,\n",
       " 1848,\n",
       " 1716,\n",
       " 871,\n",
       " 1953,\n",
       " 932,\n",
       " 215,\n",
       " 1726,\n",
       " 1885,\n",
       " 556,\n",
       " 1959,\n",
       " 6,\n",
       " 2059,\n",
       " 1230,\n",
       " 1211,\n",
       " 486,\n",
       " 1728,\n",
       " 1528,\n",
       " 2295,\n",
       " 22,\n",
       " 1594,\n",
       " 538,\n",
       " 2126,\n",
       " 1379,\n",
       " 1555,\n",
       " 2207,\n",
       " 1234,\n",
       " 423,\n",
       " 1309,\n",
       " 1384,\n",
       " 1804,\n",
       " 1386,\n",
       " 729,\n",
       " 2080,\n",
       " 1774,\n",
       " 1195,\n",
       " 649,\n",
       " 545,\n",
       " 635,\n",
       " 17,\n",
       " 1058,\n",
       " 1632,\n",
       " 2247,\n",
       " 343,\n",
       " 1790,\n",
       " 586,\n",
       " 844,\n",
       " 790,\n",
       " 84,\n",
       " 142,\n",
       " 745,\n",
       " 1380,\n",
       " 725,\n",
       " 1026,\n",
       " 1222,\n",
       " 1738,\n",
       " 2054,\n",
       " 1950,\n",
       " 1806,\n",
       " 1319,\n",
       " 1106,\n",
       " 1860,\n",
       " 892,\n",
       " 2143,\n",
       " 99,\n",
       " 1107,\n",
       " 720,\n",
       " 653,\n",
       " 1171,\n",
       " 1829,\n",
       " 1372,\n",
       " 687,\n",
       " 706,\n",
       " 1730,\n",
       " 330,\n",
       " 1894,\n",
       " 1718,\n",
       " 651,\n",
       " 1245,\n",
       " 238,\n",
       " 887,\n",
       " 640,\n",
       " 1443,\n",
       " 853,\n",
       " 1185,\n",
       " 1858,\n",
       " 291,\n",
       " 1467,\n",
       " 268,\n",
       " 37,\n",
       " 2045,\n",
       " 625,\n",
       " 1756,\n",
       " 1900,\n",
       " 1643,\n",
       " 2056,\n",
       " 957,\n",
       " 2119,\n",
       " 309,\n",
       " 32,\n",
       " 654,\n",
       " 351,\n",
       " 1256,\n",
       " 2090,\n",
       " 54,\n",
       " 1948,\n",
       " 440,\n",
       " 277,\n",
       " 1326,\n",
       " 1665,\n",
       " 1785,\n",
       " 1564,\n",
       " 2227,\n",
       " 2140,\n",
       " 270,\n",
       " 2008,\n",
       " 988,\n",
       " 2174,\n",
       " 2067,\n",
       " 1027,\n",
       " 1376,\n",
       " 535,\n",
       " 1151,\n",
       " 1800,\n",
       " 775,\n",
       " 1396,\n",
       " 208,\n",
       " 181,\n",
       " 2127,\n",
       " 1423,\n",
       " 313,\n",
       " 145,\n",
       " 955,\n",
       " 1015,\n",
       " 1204,\n",
       " 594,\n",
       " 1621,\n",
       " 319,\n",
       " 2053,\n",
       " 1260,\n",
       " 294,\n",
       " 1668,\n",
       " 168,\n",
       " 677,\n",
       " 1208,\n",
       " 794,\n",
       " 1144,\n",
       " 137,\n",
       " 792,\n",
       " 2076,\n",
       " 1114,\n",
       " 1402,\n",
       " 129,\n",
       " 213,\n",
       " 1228,\n",
       " 634,\n",
       " 549,\n",
       " 1244,\n",
       " 1651,\n",
       " 1490,\n",
       " 64,\n",
       " 1538,\n",
       " 508,\n",
       " 296,\n",
       " 1095,\n",
       " 714,\n",
       " 1388,\n",
       " 1562,\n",
       " 607,\n",
       " 2058,\n",
       " 1853,\n",
       " 1843,\n",
       " 2175,\n",
       " 2082,\n",
       " 1150,\n",
       " 385,\n",
       " 2309,\n",
       " 1333,\n",
       " 1154,\n",
       " 1104,\n",
       " 1086,\n",
       " 587,\n",
       " 1680,\n",
       " 2138,\n",
       " 322,\n",
       " 1,\n",
       " 910,\n",
       " 681,\n",
       " 1337,\n",
       " 1115,\n",
       " 2191,\n",
       " 1357,\n",
       " 2025,\n",
       " 412,\n",
       " 242,\n",
       " 789,\n",
       " 1658,\n",
       " 1895,\n",
       " 749,\n",
       " 1391,\n",
       " 2195,\n",
       " 546,\n",
       " 1085,\n",
       " 1090,\n",
       " 1009,\n",
       " 2128,\n",
       " 1838,\n",
       " 1664,\n",
       " 2092,\n",
       " 574,\n",
       " 746,\n",
       " 1714,\n",
       " 1226,\n",
       " 1970,\n",
       " 1905,\n",
       " 679,\n",
       " 1797,\n",
       " 348,\n",
       " 325,\n",
       " 1071,\n",
       " 1807,\n",
       " 1897,\n",
       " 1535,\n",
       " 1841,\n",
       " 2139,\n",
       " 310,\n",
       " 985,\n",
       " 1275,\n",
       " 1868,\n",
       " 809,\n",
       " 1469,\n",
       " 1428,\n",
       " 2134,\n",
       " 217,\n",
       " 1101,\n",
       " 1957,\n",
       " 555,\n",
       " 1332,\n",
       " 1586,\n",
       " 2000,\n",
       " 2120,\n",
       " 1072,\n",
       " 451,\n",
       " 795,\n",
       " 1434,\n",
       " 663,\n",
       " 1499,\n",
       " 2,\n",
       " 1614,\n",
       " 121,\n",
       " 1116,\n",
       " 832,\n",
       " 1662,\n",
       " 2069,\n",
       " 708,\n",
       " 2135,\n",
       " 1155,\n",
       " 1492,\n",
       " 1585,\n",
       " 1439,\n",
       " 2146,\n",
       " 1817,\n",
       " 1212,\n",
       " 2152,\n",
       " 1687,\n",
       " 156,\n",
       " 968,\n",
       " 1542,\n",
       " 1458,\n",
       " 756,\n",
       " 1192,\n",
       " 2241,\n",
       " 1186,\n",
       " 1432,\n",
       " 2032,\n",
       " 2019,\n",
       " 2278,\n",
       " 2240,\n",
       " 439,\n",
       " 1727,\n",
       " 2242,\n",
       " 2333,\n",
       " 1913,\n",
       " 2186,\n",
       " 1099,\n",
       " 885,\n",
       " 120,\n",
       " 2109,\n",
       " 1706,\n",
       " 1669,\n",
       " 1587,\n",
       " 1215,\n",
       " 2091,\n",
       " 1787,\n",
       " 308,\n",
       " 830,\n",
       " 1519,\n",
       " 1036,\n",
       " 262,\n",
       " 94,\n",
       " 1696,\n",
       " 1088,\n",
       " 638,\n",
       " 620,\n",
       " 173,\n",
       " 744,\n",
       " 1290,\n",
       " 1623,\n",
       " 190,\n",
       " 1272,\n",
       " 2142,\n",
       " 805,\n",
       " 1097,\n",
       " 1317,\n",
       " 1321,\n",
       " 1178,\n",
       " 1778,\n",
       " 2149,\n",
       " 178,\n",
       " 1652,\n",
       " 965,\n",
       " 2192,\n",
       " 67,\n",
       " 1206,\n",
       " 102,\n",
       " 2038,\n",
       " 1697,\n",
       " 1866,\n",
       " 1593,\n",
       " 1189,\n",
       " 160,\n",
       " 1657,\n",
       " 416,\n",
       " 2187,\n",
       " 2260,\n",
       " 1289,\n",
       " 755,\n",
       " 829,\n",
       " 133,\n",
       " 1851,\n",
       " 1769,\n",
       " 1265,\n",
       " 1928,\n",
       " 239,\n",
       " 1191,\n",
       " 90,\n",
       " 198,\n",
       " 601,\n",
       " 2283,\n",
       " 614,\n",
       " 2026,\n",
       " 779,\n",
       " 1742,\n",
       " 1340,\n",
       " 69,\n",
       " 370,\n",
       " 480,\n",
       " 211,\n",
       " 1749,\n",
       " 606,\n",
       " 1653,\n",
       " 2262,\n",
       " 1932,\n",
       " 665,\n",
       " 1350,\n",
       " 1855,\n",
       " 1996,\n",
       " 303,\n",
       " 2125,\n",
       " 476,\n",
       " 1364,\n",
       " 769,\n",
       " 154,\n",
       " 2221,\n",
       " 1485,\n",
       " 1221,\n",
       " 1987,\n",
       " 1013,\n",
       " 703,\n",
       " 236,\n",
       " 1266,\n",
       " 280,\n",
       " 1589,\n",
       " 1719,\n",
       " 670,\n",
       " 1849,\n",
       " 553,\n",
       " 317,\n",
       " 1682,\n",
       " 2081,\n",
       " 515,\n",
       " 1004,\n",
       " 1753,\n",
       " 234,\n",
       " 66,\n",
       " 2196,\n",
       " 1392,\n",
       " 1441,\n",
       " 1822,\n",
       " 930,\n",
       " 141,\n",
       " 2205,\n",
       " 977,\n",
       " 1227,\n",
       " 1642,\n",
       " 2224,\n",
       " 722,\n",
       " 1168,\n",
       " 2188,\n",
       " 1552,\n",
       " 1832,\n",
       " 1508,\n",
       " 1246,\n",
       " 2332,\n",
       " 810,\n",
       " 1815,\n",
       " 1166,\n",
       " 1857,\n",
       " 2299,\n",
       " 1861,\n",
       " 589,\n",
       " 324,\n",
       " 1209,\n",
       " 1902,\n",
       " 2043,\n",
       " 298,\n",
       " 1628,\n",
       " 1096,\n",
       " 436,\n",
       " 1239,\n",
       " 218,\n",
       " 1968,\n",
       " 2290,\n",
       " 2238,\n",
       " 282,\n",
       " 2066,\n",
       " 1784,\n",
       " 1464,\n",
       " 683,\n",
       " 110,\n",
       " 743,\n",
       " 821,\n",
       " 2334,\n",
       " 2237,\n",
       " 812,\n",
       " 1216,\n",
       " 179,\n",
       " 204,\n",
       " 1939,\n",
       " 1358,\n",
       " 1361,\n",
       " 1427,\n",
       " 1748,\n",
       " 2018,\n",
       " 1363,\n",
       " 1373,\n",
       " 307,\n",
       " 2212,\n",
       " 1969,\n",
       " 1570,\n",
       " 61,\n",
       " 286,\n",
       " 1693,\n",
       " 814,\n",
       " 336,\n",
       " 942,\n",
       " 86,\n",
       " 731,\n",
       " 1840,\n",
       " 1923,\n",
       " 1065,\n",
       " 1640,\n",
       " 2345,\n",
       " 646,\n",
       " 2006,\n",
       " 1888,\n",
       " 1605,\n",
       " 43,\n",
       " 685,\n",
       " 2129,\n",
       " 1924,\n",
       " 271,\n",
       " 2022,\n",
       " 1393,\n",
       " 1276,\n",
       " 1433,\n",
       " 1873,\n",
       " 843,\n",
       " 1906,\n",
       " 888,\n",
       " 1904,\n",
       " 1783,\n",
       " 501,\n",
       " 444,\n",
       " 4,\n",
       " 657,\n",
       " 191,\n",
       " 2170,\n",
       " 909,\n",
       " 2254,\n",
       " 1164,\n",
       " 1142,\n",
       " 595,\n",
       " 2042,\n",
       " 356,\n",
       " 1254,\n",
       " 1887,\n",
       " 128,\n",
       " 1647,\n",
       " 1170,\n",
       " 2020,\n",
       " 446,\n",
       " 19,\n",
       " 10,\n",
       " 1374,\n",
       " 1399,\n",
       " 822,\n",
       " 897,\n",
       " 1725,\n",
       " 1695,\n",
       " 143,\n",
       " 1731,\n",
       " 1293,\n",
       " 1661,\n",
       " 1255,\n",
       " 157,\n",
       " 1278,\n",
       " 1549,\n",
       " 1792,\n",
       " 947,\n",
       " 424,\n",
       " 971,\n",
       " 1181,\n",
       " 1174,\n",
       " 1602,\n",
       " 588,\n",
       " 1362,\n",
       " 1068,\n",
       " 1456,\n",
       " 1213,\n",
       " 550,\n",
       " 1779,\n",
       " 2292,\n",
       " 438,\n",
       " 170,\n",
       " 1461,\n",
       " 2114,\n",
       " 1824,\n",
       " 1793,\n",
       " 235,\n",
       " 1366,\n",
       " 1387,\n",
       " 1934,\n",
       " 1148,\n",
       " 1557,\n",
       " 1980,\n",
       " 1757,\n",
       " 1196,\n",
       " 1235,\n",
       " 104,\n",
       " 931,\n",
       " 1412,\n",
       " 1708,\n",
       " 826,\n",
       " 982,\n",
       " 132,\n",
       " 96,\n",
       " 478,\n",
       " 719,\n",
       " 1229,\n",
       " 338,\n",
       " 1342,\n",
       " 1553,\n",
       " 1588,\n",
       " 1942,\n",
       " 327,\n",
       " 27,\n",
       " 705,\n",
       " 2178,\n",
       " 1277,\n",
       " 1581,\n",
       " 1236,\n",
       " 1898,\n",
       " 2163,\n",
       " 752,\n",
       " 2228,\n",
       " 2219,\n",
       " 1334,\n",
       " 851,\n",
       " 2095,\n",
       " 2265,\n",
       " 1180,\n",
       " 1503,\n",
       " 1691,\n",
       " 2302,\n",
       " 354,\n",
       " 152,\n",
       " 1291,\n",
       " 1683,\n",
       " 382,\n",
       " 29,\n",
       " 997,\n",
       " 1865,\n",
       " 352,\n",
       " 688,\n",
       " 1755,\n",
       " 2344,\n",
       " 566,\n",
       " 2055,\n",
       " 1759,\n",
       " 1723,\n",
       " 650,\n",
       " 1791,\n",
       " 1692,\n",
       " 1819,\n",
       " 597,\n",
       " 610,\n",
       " 185,\n",
       " 999,\n",
       " 1678,\n",
       " 93,\n",
       " 1417,\n",
       " 1810,\n",
       " 1295,\n",
       " 813,\n",
       " 978,\n",
       " 1830,\n",
       " 2217,\n",
       " 2272,\n",
       " 1303,\n",
       " 241,\n",
       " 669,\n",
       " 791,\n",
       " 2294,\n",
       " 2039,\n",
       " 964,\n",
       " 1194,\n",
       " 583,\n",
       " 1978,\n",
       " 124,\n",
       " 1292,\n",
       " 2169,\n",
       " 626,\n",
       " 855,\n",
       " 125,\n",
       " 541,\n",
       " 591,\n",
       " 995,\n",
       " 425,\n",
       " 1282,\n",
       " 577,\n",
       " 2071,\n",
       " 1864,\n",
       " 1820,\n",
       " 630,\n",
       " 1965,\n",
       " 1394,\n",
       " 862,\n",
       " 1852,\n",
       " 1328,\n",
       " 1481,\n",
       " 1288,\n",
       " 105,\n",
       " 1717,\n",
       " 1411,\n",
       " 1576,\n",
       " 158,\n",
       " 1740,\n",
       " 1197,\n",
       " 273,\n",
       " 222,\n",
       " ...]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Function to get scores for evrey user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_suggestion(user,k) : \n",
    "    item_score_map = dict()\n",
    "    items, scores = model.get_scores(sess, {model.user_indices: [user] * len(movie_set),\n",
    "                                            model.item_indices: list(movie_set),\n",
    "                                            model.head_indices: list(movie_set)})\n",
    "    for item, score in zip(items, scores):\n",
    "            item_score_map[item] = score\n",
    "\n",
    "    item_score_pair_sorted = sorted(item_score_map.items(), key=lambda x: x[1], reverse=True)\n",
    "    item_sorted = [i[0] for i in item_score_pair_sorted]\n",
    "    \n",
    "    return item_score_pair_sorted[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_truth(user, k):\n",
    "    if user not in truth_dict:\n",
    "        return []\n",
    "    #ERASE [:k]\n",
    "    return truth_dict[user]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intersect_pred_truth(pred, truth, k):\n",
    "    pred_item_set = {x[0] for x in pred}\n",
    "    truth_item_set = set(truth)\n",
    "    \n",
    "    return pred_item_set.intersection(truth_item_set)\n",
    "\n",
    "def check_precision_at_k(sample_user, k):\n",
    "    \n",
    "    pred = get_top_suggestion(sample_user, k)\n",
    "    truth = get_top_truth(sample_user, k)\n",
    "    \n",
    "    intersect = get_intersect_pred_truth(pred, truth, k)\n",
    "    \n",
    "    if len(truth) > 0 :\n",
    "        return intersect, len(intersect) / len(truth)\n",
    "    else:\n",
    "        return {}, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create n user of sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(1234)\n",
    "\n",
    "user_sample_500 = random.sample(user_set,500)\n",
    "user_sample_1000 = random.sample(user_set,1000)\n",
    "user_sample_3000 = random.sample(user_set,3000)\n",
    "user_sample_5000 = random.sample(user_set,5000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the precision ot K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 500 user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:02<00:00, 243.88it/s]\n"
     ]
    }
   ],
   "source": [
    "prec = []\n",
    "intersect = []\n",
    "\n",
    "for i in tqdm(user_sample_500):\n",
    "    \n",
    "    try:\n",
    "        isec, p = check_precision_at_k(i, 10)\n",
    "    except:\n",
    "        p = 0\n",
    "        isec = {}\n",
    "        print(\"error occur for {}\".format(i))\n",
    "        \n",
    "    prec.append(p)\n",
    "    intersect.append(isec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08280191963741572"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.average(prec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:04<00:00, 243.88it/s]\n"
     ]
    }
   ],
   "source": [
    "prec = []\n",
    "intersect = []\n",
    "\n",
    "for i in tqdm(user_sample_1000):\n",
    "    \n",
    "    try:\n",
    "        isec, p = check_precision_at_k(i, 10)\n",
    "    except:\n",
    "        p = 0\n",
    "        isec = {}\n",
    "        print(\"error occur for {}\".format(i))\n",
    "        \n",
    "    prec.append(p)\n",
    "    intersect.append(isec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0838251287102731"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.average(prec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:12<00:00, 242.15it/s]\n"
     ]
    }
   ],
   "source": [
    "prec = []\n",
    "intersect = []\n",
    "\n",
    "for i in tqdm(user_sample_3000):\n",
    "    \n",
    "    try:\n",
    "        isec, p = check_precision_at_k(i, 10)\n",
    "    except:\n",
    "        p = 0\n",
    "        isec = {}\n",
    "        print(\"error occur for {}\".format(i))\n",
    "        \n",
    "    prec.append(p)\n",
    "    intersect.append(isec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08095399514205776"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.average(prec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:20<00:00, 241.18it/s]\n"
     ]
    }
   ],
   "source": [
    "prec = []\n",
    "intersect = []\n",
    "\n",
    "for i in tqdm(user_sample_5000):\n",
    "    \n",
    "    try:\n",
    "        isec, p = check_precision_at_k(i, 10)\n",
    "    except:\n",
    "        p = 0\n",
    "        isec = {}\n",
    "        print(\"error occur for {}\".format(i))\n",
    "        \n",
    "    prec.append(p)\n",
    "    intersect.append(isec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08243254951731796"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.average(prec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 500 sample user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "distinct rate\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "offset = 190 # discard top n suggestion\n",
    "k = 10\n",
    "\n",
    "sample_user = user_sample_500\n",
    "\n",
    "intersect = {x[1] for x in get_top_suggestion(sample_user[0], k + offset)[offset:]}\n",
    "uni = intersect\n",
    "for i in range(1, 10):\n",
    "    s = {x[1] for x in get_top_suggestion(sample_user[i], k + offset)[offset:]}\n",
    "    #print(sorted(s))\n",
    "    intersect = intersect.intersection(s)\n",
    "    uni = uni.union(s)\n",
    "    \n",
    "#print(\"\\nintersect\")\n",
    "#print(intersect, len(intersect))\n",
    "#print(\"\\nunion\")\n",
    "#print(uni, len(uni))\n",
    "print(\"\\ndistinct rate\")\n",
    "print((len(uni)) / (10*k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1000 sample user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 239.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "distinct rate\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "offset = 190 # discard top n suggestion\n",
    "k = 10\n",
    "\n",
    "sample_user = user_sample_1000\n",
    "\n",
    "intersect = {x[1] for x in get_top_suggestion(sample_user[0], k + offset)[offset:]}\n",
    "uni = intersect\n",
    "for i in tqdm(range(1, 10)):\n",
    "    s = {x[1] for x in get_top_suggestion(sample_user[i], k + offset)[offset:]}\n",
    "    #print(sorted(s))\n",
    "    intersect = intersect.intersection(s)\n",
    "    uni = uni.union(s)\n",
    "    \n",
    "#print(\"\\nintersect\")\n",
    "#print(intersect, len(intersect))\n",
    "#print(\"\\nunion\")\n",
    "#print(uni, len(uni))\n",
    "print(\"\\ndistinct rate\")\n",
    "print((len(uni)) / (10*k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3000 sample user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 243.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "distinct rate\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "offset = 190 # discard top n suggestion\n",
    "k = 10\n",
    "\n",
    "sample_user = user_sample_3000\n",
    "\n",
    "intersect = {x[1] for x in get_top_suggestion(sample_user[0], k + offset)[offset:]}\n",
    "uni = intersect\n",
    "for i in tqdm(range(1, 10)):\n",
    "    s = {x[1] for x in get_top_suggestion(sample_user[i], k + offset)[offset:]}\n",
    "    #print(sorted(s))\n",
    "    intersect = intersect.intersection(s)\n",
    "    uni = uni.union(s)\n",
    "    \n",
    "#print(\"\\nintersect\")\n",
    "#print(intersect, len(intersect))\n",
    "#print(\"\\nunion\")\n",
    "#print(uni, len(uni))\n",
    "print(\"\\ndistinct rate\")\n",
    "print((len(uni)) / (10*k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5000 sample user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 231.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "distinct rate\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "offset = 190 # discard top n suggestion\n",
    "k = 10\n",
    "\n",
    "sample_user = user_sample_5000\n",
    "\n",
    "intersect = {x[1] for x in get_top_suggestion(sample_user[0], k + offset)[offset:]}\n",
    "uni = intersect\n",
    "for i in tqdm(range(1, 10)):\n",
    "    s = {x[1] for x in get_top_suggestion(sample_user[i], k + offset)[offset:]}\n",
    "    #print(sorted(s))\n",
    "    intersect = intersect.intersection(s)\n",
    "    uni = uni.union(s)\n",
    "    \n",
    "#print(\"\\nintersect\")\n",
    "#print(intersect, len(intersect))\n",
    "#print(\"\\nunion\")\n",
    "#print(uni, len(uni))\n",
    "print(\"\\ndistinct rate\")\n",
    "print((len(uni)) / (10*k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Unique Movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 500 sample user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:02<00:00, 245.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "unique_movies = set()\n",
    "\n",
    "for user in tqdm(user_sample_500) :    \n",
    "    pred = get_top_suggestion(user,10)\n",
    "    for x in pred :\n",
    "        unique_movies.add(x[0])\n",
    "        \n",
    "print(len(unique_movies))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1000 sample user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:04<00:00, 245.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "unique_movies = set()\n",
    "\n",
    "for user in tqdm(user_sample_1000) :    \n",
    "    pred = get_top_suggestion(user,10)\n",
    "    for x in pred :\n",
    "        unique_movies.add(x[0])\n",
    "        \n",
    "print(len(unique_movies))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3000 sample user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:12<00:00, 243.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "unique_movies = set()\n",
    "\n",
    "for user in tqdm(user_sample_3000) :    \n",
    "    pred = get_top_suggestion(user,10)\n",
    "    for x in pred :\n",
    "        unique_movies.add(x[0])\n",
    "        \n",
    "print(len(unique_movies))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5000 sample user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:20<00:00, 242.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "unique_movies = set()\n",
    "\n",
    "for user in tqdm(user_sample_5000) :    \n",
    "    pred = get_top_suggestion(user,10)\n",
    "    for x in pred :\n",
    "        unique_movies.add(x[0])\n",
    "        \n",
    "print(len(unique_movies))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate top k recommendation for 10 selected user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = get_top_suggestion(125,10)\n",
    "pred_set = [x[0] for x in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[333, 31, 1381, 1680, 184, 201, 1595, 1548, 1846, 1739]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(truth_dict[125]).intersection(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2164, 4106, 5516, 4583, 1637, 236, 779, 5651, 4920, 1252]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#user_test_list = [20169,66966,82374,4296,10204,123623,115870,128970,83750,97239]\n",
    "user_test_list = random.sample(user_set,10)\n",
    "user_test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_pred_dict = {}\n",
    "\n",
    "for user in user_test_list :\n",
    "    pred_tuple = get_top_suggestion(user-1,10)\n",
    "    pred = [x[0] for x in pred_tuple]\n",
    "    topk_pred_dict[user] = pred    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2164: [694, 162, 2075, 371, 736, 704, 651, 301, 1483, 793],\n",
       " 4106: [694, 162, 736, 371, 704, 301, 1613, 1483, 651, 2075],\n",
       " 5516: [694, 736, 162, 1613, 371, 704, 808, 734, 341, 636],\n",
       " 4583: [2075, 371, 1483, 162, 1512, 2243, 301, 704, 781, 694],\n",
       " 1637: [2075, 700, 371, 731, 162, 1483, 694, 1208, 704, 341],\n",
       " 236: [333, 1381, 1159, 1595, 371, 694, 734, 1483, 0, 184],\n",
       " 779: [700, 694, 1483, 371, 333, 31, 184, 1595, 162, 1551],\n",
       " 5651: [333, 31, 184, 1680, 734, 1595, 201, 1381, 1846, 374],\n",
       " 4920: [333, 31, 1680, 1381, 201, 1548, 184, 1846, 1739, 1595],\n",
       " 1252: [333, 1381, 31, 201, 12, 184, 684, 227, 724, 807]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_pred_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert ID to Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = open(\"../data/intersect-14m/moviesIdx2.txt\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_entities = {}\n",
    "for movie in movies:\n",
    "    x = movie.strip().split()\n",
    "    movie_id = int(x[0])\n",
    "    movie_name = x[1]\n",
    "    dict_entities[movie_id] = movie_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_movie(id_movie_list, truth_list) :\n",
    "    res = []\n",
    "    for id_movie in id_movie_list :\n",
    "        is_watched = \"watched\" if id_movie in truth_list else \"nope\"\n",
    "        content = dict_entities[int(id_movie)] + \" > \" + is_watched \n",
    "        res.append(content)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_pred_dict_title = {}\n",
    "\n",
    "for user in topk_pred_dict.keys() :\n",
    "    topk_pred_dict_title[user] = get_list_movie(topk_pred_dict[user],truth_dict[user])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2164: ['http://dbpedia.org/resource/American_Heart > watched',\n",
       "  'http://dbpedia.org/resource/3_Bad_Men > watched',\n",
       "  'http://dbpedia.org/resource/Branded_(1920_film) > watched',\n",
       "  'http://dbpedia.org/resource/Adam_Resurrected > watched',\n",
       "  'http://dbpedia.org/resource/American_Wedding > nope',\n",
       "  'http://dbpedia.org/resource/American_Mullet > watched',\n",
       "  'http://dbpedia.org/resource/Always_Leave_Them_Laughing > watched',\n",
       "  'http://dbpedia.org/resource/Abduction_(2011_film) > watched',\n",
       "  'http://dbpedia.org/resource/Belly_(film) > watched',\n",
       "  'http://dbpedia.org/resource/And_When_Did_You_Last_See_Your_Father%3F > nope'],\n",
       " 4106: ['http://dbpedia.org/resource/American_Heart > nope',\n",
       "  'http://dbpedia.org/resource/3_Bad_Men > nope',\n",
       "  'http://dbpedia.org/resource/American_Wedding > nope',\n",
       "  'http://dbpedia.org/resource/Adam_Resurrected > nope',\n",
       "  'http://dbpedia.org/resource/American_Mullet > nope',\n",
       "  'http://dbpedia.org/resource/Abduction_(2011_film) > nope',\n",
       "  'http://dbpedia.org/resource/Big_Boys_Gone_Bananas!* > nope',\n",
       "  'http://dbpedia.org/resource/Belly_(film) > nope',\n",
       "  'http://dbpedia.org/resource/Always_Leave_Them_Laughing > nope',\n",
       "  'http://dbpedia.org/resource/Branded_(1920_film) > nope'],\n",
       " 5516: ['http://dbpedia.org/resource/American_Heart > nope',\n",
       "  'http://dbpedia.org/resource/American_Wedding > nope',\n",
       "  'http://dbpedia.org/resource/3_Bad_Men > nope',\n",
       "  'http://dbpedia.org/resource/Big_Boys_Gone_Bananas!* > nope',\n",
       "  'http://dbpedia.org/resource/Adam_Resurrected > nope',\n",
       "  'http://dbpedia.org/resource/American_Mullet > nope',\n",
       "  'http://dbpedia.org/resource/Angel_Baby_(1995_film) > nope',\n",
       "  'http://dbpedia.org/resource/American_Violet > watched',\n",
       "  'http://dbpedia.org/resource/Ace_Attorney_(film) > watched',\n",
       "  'http://dbpedia.org/resource/Alpha_and_Omega_(film) > nope'],\n",
       " 4583: ['http://dbpedia.org/resource/Branded_(1920_film) > nope',\n",
       "  'http://dbpedia.org/resource/Adam_Resurrected > nope',\n",
       "  'http://dbpedia.org/resource/Belly_(film) > nope',\n",
       "  'http://dbpedia.org/resource/3_Bad_Men > nope',\n",
       "  'http://dbpedia.org/resource/Beowulf_(2007_film) > nope',\n",
       "  \"http://dbpedia.org/resource/Buffalo_'66 > nope\",\n",
       "  'http://dbpedia.org/resource/Abduction_(2011_film) > nope',\n",
       "  'http://dbpedia.org/resource/American_Mullet > watched',\n",
       "  'http://dbpedia.org/resource/Anchorman_2:_The_Legend_Continues > nope',\n",
       "  'http://dbpedia.org/resource/American_Heart > nope'],\n",
       " 1637: ['http://dbpedia.org/resource/Branded_(1920_film) > nope',\n",
       "  'http://dbpedia.org/resource/American_Madness > nope',\n",
       "  'http://dbpedia.org/resource/Adam_Resurrected > nope',\n",
       "  'http://dbpedia.org/resource/American_Swing > nope',\n",
       "  'http://dbpedia.org/resource/3_Bad_Men > nope',\n",
       "  'http://dbpedia.org/resource/Belly_(film) > nope',\n",
       "  'http://dbpedia.org/resource/American_Heart > nope',\n",
       "  'http://dbpedia.org/resource/Bad_Girls_(2012_film) > nope',\n",
       "  'http://dbpedia.org/resource/American_Mullet > nope',\n",
       "  'http://dbpedia.org/resource/Ace_Attorney_(film) > nope'],\n",
       " 236: ['http://dbpedia.org/resource/Accepted > nope',\n",
       "  'http://dbpedia.org/resource/Beaufort_(film) > nope',\n",
       "  'http://dbpedia.org/resource/Bachelor_Party_(2012_film) > nope',\n",
       "  'http://dbpedia.org/resource/Beyond_the_Rocks_(film) > watched',\n",
       "  'http://dbpedia.org/resource/Adam_Resurrected > nope',\n",
       "  'http://dbpedia.org/resource/American_Heart > nope',\n",
       "  'http://dbpedia.org/resource/American_Violet > watched',\n",
       "  'http://dbpedia.org/resource/Belly_(film) > nope',\n",
       "  'http://dbpedia.org/resource/$9.99 > watched',\n",
       "  'http://dbpedia.org/resource/48_Shades > nope'],\n",
       " 779: ['http://dbpedia.org/resource/American_Madness > watched',\n",
       "  'http://dbpedia.org/resource/American_Heart > watched',\n",
       "  'http://dbpedia.org/resource/Belly_(film) > watched',\n",
       "  'http://dbpedia.org/resource/Adam_Resurrected > watched',\n",
       "  'http://dbpedia.org/resource/Accepted > nope',\n",
       "  'http://dbpedia.org/resource/11.6 > nope',\n",
       "  'http://dbpedia.org/resource/48_Shades > watched',\n",
       "  'http://dbpedia.org/resource/Beyond_the_Rocks_(film) > nope',\n",
       "  'http://dbpedia.org/resource/3_Bad_Men > watched',\n",
       "  'http://dbpedia.org/resource/Better_This_World > nope'],\n",
       " 5651: ['http://dbpedia.org/resource/Accepted > watched',\n",
       "  'http://dbpedia.org/resource/11.6 > nope',\n",
       "  'http://dbpedia.org/resource/48_Shades > nope',\n",
       "  'http://dbpedia.org/resource/Bird_(film) > nope',\n",
       "  'http://dbpedia.org/resource/American_Violet > watched',\n",
       "  'http://dbpedia.org/resource/Beyond_the_Rocks_(film) > nope',\n",
       "  'http://dbpedia.org/resource/5_Days_of_War > watched',\n",
       "  'http://dbpedia.org/resource/Beaufort_(film) > watched',\n",
       "  'http://dbpedia.org/resource/Blood_Games_(film) > nope',\n",
       "  'http://dbpedia.org/resource/Adanggaman > watched'],\n",
       " 4920: ['http://dbpedia.org/resource/Accepted > watched',\n",
       "  'http://dbpedia.org/resource/11.6 > watched',\n",
       "  'http://dbpedia.org/resource/Bird_(film) > nope',\n",
       "  'http://dbpedia.org/resource/Beaufort_(film) > watched',\n",
       "  'http://dbpedia.org/resource/5_Days_of_War > watched',\n",
       "  'http://dbpedia.org/resource/Better_Than_Chocolate > nope',\n",
       "  'http://dbpedia.org/resource/48_Shades > nope',\n",
       "  'http://dbpedia.org/resource/Blood_Games_(film) > nope',\n",
       "  'http://dbpedia.org/resource/Black_Orpheus > nope',\n",
       "  'http://dbpedia.org/resource/Beyond_the_Rocks_(film) > nope'],\n",
       " 1252: ['http://dbpedia.org/resource/Accepted > nope',\n",
       "  'http://dbpedia.org/resource/Beaufort_(film) > nope',\n",
       "  'http://dbpedia.org/resource/11.6 > nope',\n",
       "  'http://dbpedia.org/resource/5_Days_of_War > nope',\n",
       "  'http://dbpedia.org/resource/1001_Nights_(film) > nope',\n",
       "  'http://dbpedia.org/resource/48_Shades > nope',\n",
       "  'http://dbpedia.org/resource/American_Drug_War:_The_Last_White_Hope > nope',\n",
       "  'http://dbpedia.org/resource/8_Women > nope',\n",
       "  'http://dbpedia.org/resource/American_Samurai_(film) > nope',\n",
       "  'http://dbpedia.org/resource/Angel_(2011_film) > nope']}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_pred_dict_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "topk_pred_df = pd.DataFrame(topk_pred_dict_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_pred_df.to_csv('topk_pred2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
